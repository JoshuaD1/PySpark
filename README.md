<h1> Database Manegement using PySpark </h1>

<h2> Description </h2>
Project consists of becoming familiar with PySpark for big data applications. Spark is useful for applications that require a highly distributed persistent, pipelined processing, and alot of calculations (e.g., Natural Language Processing and Computer Vision). A typical rule-of-thump is start a project in Pandas with a limited sample <b> less than 1 millions rows and 1000 columns</b> and later migrate to Spark.

<ol>
  <br/>
  <li> Part 1: Creating Dataframe, Retrieving Data, Visualizing Dataframe 
  <li> Part 2: Updating Dataframe, Manipulating Dataframe, Imputing Missing Values
  <li> Part 3: Filtering & Sorting, Filtering by conditions & values
  <li> Part 4: Machine Learning
</ol>

<h2> Environment </h2>
<ul>
  <li><b> Python 3.0+ </b>
  <li><b> Google Colab </b>
</ul>
